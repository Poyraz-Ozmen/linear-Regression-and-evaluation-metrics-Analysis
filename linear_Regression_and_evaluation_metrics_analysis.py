# -*- coding: utf-8 -*-
"""HW4_LinearRegression (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1X88oLCuVCpv6LQ3uHkPpQE3ZO4NiIM0m

# Load the dataset
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt                   

df = pd.read_csv('https://raw.githubusercontent.com/OpenClassrooms-Student-Center/Evaluate-Improve-Models/master/house_prices.csv')
df.sample(5)

"""# "Garage Area" and "SalesPrice" features are selected to analyze."""

new_df = df[['Garage Area','SalesPrice']]
new_df.sample(5)

"""## Convert the data into numpy arrays of two variables, X and y."""

X = np.array(new_df[['Garage Area']])
y = np.array(new_df[['SalesPrice']]) 
print(X.shape) # Vewing the shape of X
print(y.shape) # Vewing the shape of y

"""## Split train and test data with 0.2 ratio."""

from sklearn.model_selection import train_test_split
# Spliting into train & test dataset
X_train,X_test,y_train,y_test = train_test_split(X, y, test_size = 0.2,random_state=15)

"""# Linear Regression
Train a linear regression.
"""

from sklearn import linear_model 

# Creating a regressior model
regressor = linear_model.LinearRegression()
# Fiting the dataset into the model
regressor.fit(X_train,y_train)

"""## Calculate train and test R2."""

from sklearn.metrics import r2_score

y_pred = regressor.predict(X_train)

y_pred2 = regressor.predict(X_test)
# R^2 (coefficient of determination) regression score function.

# code comes here
print("Train:", r2_score(y_train,y_pred)) 

# code comes here
print("Test:", r2_score(y_test,y_pred2))

"""## Print the bias and the slope."""

print('Regressor coeffient or slope:',regressor.coef_[0][0])
print('Interception point with axis:',regressor.intercept_[0])

"""## Plot the test set with scatter plot and add the linear regression model line.
Remember linear regression recitation.
"""

less_data = np.random.choice(606, 15)
d_X_train = X_train[less_data]
d_y_train = y_train[less_data]
regressor.fit(d_X_train,d_y_train) 

# Plot a graph with X_test vs y_test
plt.scatter(X_test,y_test,color="green")

# Regressior line showing
plt.plot(d_X_train,regressor.predict(d_X_train),color="red",linewidth=3)
plt.title('Regression(Test Set)')
plt.xlabel('Garage Area')
plt.ylabel('SalesPrice')
plt.show()

"""# Multiple Linear Regression
Select all features.
"""

df2  = df.drop('SalesPrice', axis=1)

df3 = df2.fillna(0.0).astype(int)
X = df3
y = df[['SalesPrice']]

print(X.shape) # Vewing the shape of X
print(y.shape) # Vewing the shape of y

"""## Rescale the input features. Use MinMaxScaler.

---



---

*italicized text*
"""

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
X = scaler.fit_transform(X)

'''
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
X = # code comes here
'''
#df.dtypes

"""## Train test split."""

x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=15)

"""## Fit regression model."""

# Creating a regressior model
regressor = linear_model.LinearRegression()
# Fiting the dataset into the model
regressor.fit(X_train,y_train)

"""## Calculate train and test R2."""

y_pred = regressor.predict(X_train)

y_pred2 = regressor.predict(X_test)
# R^2 (coefficient of determination) regression score function.

# code comes here
print("Train:", r2_score(y_train,y_pred)) 

# code comes here
print("Test:", r2_score(y_test,y_pred2))

"""## Print the regression coefficients."""

print('Regressor coeffients for multiple linear regression:',regressor.coef_[0][0])

print('Interception point with axis:',regressor.intercept_[0])

"""# Ridge Regression
https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html

https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html

## Use cross-validation to estimate alpha. Set the fold size to 5.
"""

from sklearn.model_selection import KFold
from sklearn.linear_model import RidgeCV
kfold = KFold(n_splits=5)

alphas=[1e-3, 1e-2, 1e-1, 1, 2, 5, 8, 10]
# Create and fit model
model_rcv = RidgeCV(alphas).fit(X, y)

model_rcv_temp = RidgeCV(alphas).fit(X, y)
# code comes here
model_rcv.score(X, y)
model_rcv_temp.score(X, y)

"""## Calculate the train and test R2."""

from sklearn.linear_model import Ridge
#rr = Ridge(alphas)
#rr.fit(X_train, y_train) 

rr = Ridge(alpha=5)
rr.fit(X_train, y_train) 

pred_train_rr= rr.predict(X_train)
print('Train: ',r2_score(y_train, pred_train_rr))

pred_test_rr= rr.predict(X_test)
print('Test: ',r2_score(y_test, pred_test_rr))

"""## Print the best alpha."""

print("Alpha:", model_rcv.alpha_)

"""## Print the regression coefficients."""

coefs = []
for a in alphas:
    ridge = linear_model.Ridge(alpha=a, fit_intercept=False)
    ridge.fit(X, y)
    coefs.append(ridge.coef_)

# Creating a regressior model
regressor = linear_model.LinearRegression()
# Fiting the dataset into the model
regressor.fit(X_train,y_train) 
print('Regressor coeffients for ridge regression:',regressor.coef_[0][0])
print('***********')

print('coefs:',coefs[0][0])

## This is Part B in HW

from sklearn import metrics

# Constants
O="Orange"
L="Lemon"
A="Apple"

# True values
y_true = [O,O,O,O,O,L,L,A,A]
# Predicted values
y_pred = [L,L,A,O,A,L,A,A,A]

# Print the confusion matrix
print(metrics.confusion_matrix(y_true, y_pred))

# Print the precision and recall, among other metrics
print(metrics.classification_report(y_true, y_pred, digits=3))